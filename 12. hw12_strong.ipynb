{"cells":[{"cell_type":"markdown","metadata":{"id":"Fp30SB4bxeQb"},"source":["# **Homework 12 - Reinforcement Learning**\n","\n","If you have any problem, e-mail us at ntu-ml-2022spring-ta@googlegroups.com\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yXsnCWPtWSNk"},"source":["## Preliminary work\n","\n","First, we need to install all necessary packages.\n","One of them, gym, builded by OpenAI, is a toolkit for developing Reinforcement Learning algorithm. Other packages are for visualization in colab."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5e2bScpnkVbv","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1657821914210,"user_tz":-480,"elapsed":146174,"user":{"displayName":"熾炎使者","userId":"06511828832705263711"}},"outputId":"72d0afe9-1887-43d2-d2a5-f5b3efb2bcf1"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Connecting to security.ub\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","\r                                                                               \rHit:3 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","\r                                                                               \rHit:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","\r                                                                               \rHit:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","\r                                                                               \rHit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\u001b[33m\r                                                                               \r0% [Waiting for headers] [Waiting for headers] [Waiting for headers]\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Waiting for headers] [Wait\u001b[0m\r                                                                               \rGet:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:14 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,057 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,329 kB]\n","Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,526 kB]\n","Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,897 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,302 kB]\n","Fetched 11.4 MB in 5s (2,231 kB/s)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","63 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","Suggested packages:\n","  libgle3\n","The following NEW packages will be installed:\n","  python-opengl xvfb\n","0 upgraded, 2 newly installed, 0 to remove and 63 not upgraded.\n","Need to get 1,281 kB of archives.\n","After this operation, 7,687 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.11 [785 kB]\n","Fetched 1,281 kB in 1s (1,453 kB/s)\n","Selecting previously unselected package python-opengl.\n","(Reading database ... 155653 files and directories currently installed.)\n","Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n","Unpacking python-opengl (3.1.0+dfsg-1) ...\n","Selecting previously unselected package xvfb.\n","Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.11_amd64.deb ...\n","Unpacking xvfb (2:1.19.6-1ubuntu4.11) ...\n","Setting up python-opengl (3.1.0+dfsg-1) ...\n","Setting up xvfb (2:1.19.6-1ubuntu4.11) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gym[box2d]==0.18.3\n","  Downloading gym-0.18.3.tar.gz (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 15.4 MB/s \n","\u001b[?25hCollecting pyvirtualdisplay\n","  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n","Collecting numpy==1.19.5\n","  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n","\u001b[K     |████████████████████████████████| 14.8 MB 61.6 MB/s \n","\u001b[?25hCollecting torch==1.8.1\n","  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n","\u001b[K     |████████████████████████████████| 804.1 MB 2.5 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (4.1.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.7.3)\n","Requirement already satisfied: pyglet<=1.5.15,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.5.0)\n","Requirement already satisfied: Pillow<=8.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (7.1.2)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.3.0)\n","Collecting box2d-py~=2.3.5\n","  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 54.7 MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.15,>=1.4.0->gym[box2d]==0.18.3) (0.16.0)\n","Building wheels for collected packages: gym\n","  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.18.3-py3-none-any.whl size=1657532 sha256=3dbd1b32b8d1ddf39a4afc8b0a77bb4b753aeef026cd52daf0b2002e593485b6\n","  Stored in directory: /root/.cache/pip/wheels/1a/ec/6d/705d53925f481ab70fd48ec7728558745eeae14dfda3b49c99\n","Successfully built gym\n","Installing collected packages: numpy, gym, box2d-py, torch, pyvirtualdisplay\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.17.3\n","    Uninstalling gym-0.17.3:\n","      Successfully uninstalled gym-0.17.3\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.0+cu113\n","    Uninstalling torch-1.12.0+cu113:\n","      Successfully uninstalled torch-1.12.0+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n","torchvision 0.13.0+cu113 requires torch==1.12.0, but you have torch 1.8.1 which is incompatible.\n","torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.8.1 which is incompatible.\n","torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.8.1 which is incompatible.\n","tensorflow 2.8.2+zzzcolab20220527125636 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed box2d-py-2.3.8 gym-0.18.3 numpy-1.19.5 pyvirtualdisplay-3.0 torch-1.8.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}}],"source":["!apt update\n","!apt install python-opengl xvfb -y\n","!pip install gym[box2d]==0.18.3 pyvirtualdisplay tqdm numpy==1.19.5 torch==1.8.1"]},{"cell_type":"markdown","metadata":{"id":"M_-i3cdoYsks"},"source":["\n","Next, set up virtual display，and import all necessaary packages."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nl2nREINDLiw"},"outputs":[],"source":["%%capture\n","from pyvirtualdisplay import Display\n","virtual_display = Display(visible=0, size=(1400, 900))\n","virtual_display.start()\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","from IPython import display\n","\n","import numpy as np\n","\n","from collections import deque, namedtuple\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.distributions import Categorical\n","from tqdm.notebook import tqdm"]},{"cell_type":"markdown","metadata":{"id":"CaEJ8BUCpN9P"},"source":["# Warning ! Do not revise random seed !!!\n","# Your submission on JudgeBoi will not reproduce your result !!!\n","Make your HW result to be reproducible.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fV9i8i2YkRbO"},"outputs":[],"source":["seed = 543 # Do not change this\n","def fix(env, seed):\n","  env.seed(seed)\n","  env.action_space.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n","  np.random.seed(seed)\n","  random.seed(seed)\n","  torch.set_deterministic(True)\n","  torch.backends.cudnn.benchmark = False\n","  torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","metadata":{"id":"He0XDx6bzjgC"},"source":["Last, call gym and build an [Lunar Lander](https://gym.openai.com/envs/LunarLander-v2/) environment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N_4-xJcbBt09"},"outputs":[],"source":["%%capture\n","import gym\n","import random\n","env = gym.make('LunarLander-v2')\n","fix(env, seed) # fix the environment Do not revise this !!!"]},{"cell_type":"markdown","metadata":{"id":"NrkVvTrvWZ5H"},"source":["## What Lunar Lander？\n","\n","“LunarLander-v2”is to simulate the situation when the craft lands on the surface of the moon.\n","\n","This task is to enable the craft to land \"safely\" at the pad between the two yellow flags.\n","> Landing pad is always at coordinates (0,0).\n","> Coordinates are the first two numbers in state vector.\n","\n","![](https://gym.openai.com/assets/docs/aeloop-138c89d44114492fd02822303e6b4b07213010bb14ca5856d2d49d6b62d88e53.svg)\n","\n","\"LunarLander-v2\" actually includes \"Agent\" and \"Environment\". \n","\n","In this homework, we will utilize the function `step()` to control the action of \"Agent\". \n","\n","Then `step()` will return the observation/state and reward given by the \"Environment\"."]},{"cell_type":"markdown","metadata":{"id":"bIbp82sljvAt"},"source":["### Observation / State\n","\n","First, we can take a look at what an Observation / State looks like."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rsXZra3N9R5T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657821916268,"user_tz":-480,"elapsed":13,"user":{"displayName":"熾炎使者","userId":"06511828832705263711"}},"outputId":"c919cf77-5221-4599-e702-18e7ea18788a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Box(-inf, inf, (8,), float32)\n"]}],"source":["print(env.observation_space)"]},{"cell_type":"markdown","metadata":{"id":"ezdfoThbAQ49"},"source":["\n","`Box(8,)`means that observation is an 8-dim vector\n","### Action\n","\n","Actions can be taken by looks like"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p1k4dIrBAaKi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657821916268,"user_tz":-480,"elapsed":9,"user":{"displayName":"熾炎使者","userId":"06511828832705263711"}},"outputId":"0da1c1fd-2e87-4e04-9fa4-1ff110ca97c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Discrete(4)\n"]}],"source":["print(env.action_space)"]},{"cell_type":"markdown","metadata":{"id":"dejXT6PHBrPn"},"source":["`Discrete(4)` implies that there are four kinds of actions can be taken by agent.\n","- 0 implies the agent will not take any actions\n","- 2 implies the agent will accelerate downward\n","- 1, 3 implies the agent will accelerate left and right\n","\n","Next, we will try to make the agent interact with the environment. \n","Before taking any actions, we recommend to call `reset()` function to reset the environment. Also, this function will return the initial state of the environment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pi4OmrmZgnWA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657821916268,"user_tz":-480,"elapsed":8,"user":{"displayName":"熾炎使者","userId":"06511828832705263711"}},"outputId":"8e521909-9be6-4140-838e-1965b8de7d5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[ 0.00396109  1.4083536   0.40119505 -0.11407257 -0.00458307 -0.09087662\n","  0.          0.        ]\n"]}],"source":["initial_state = env.reset()\n","print(initial_state)"]},{"cell_type":"markdown","metadata":{"id":"uBx0mEqqgxJ9"},"source":["Then, we try to get a random action from the agent's action space."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vxkOEXRKgizt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657821916269,"user_tz":-480,"elapsed":7,"user":{"displayName":"熾炎使者","userId":"06511828832705263711"}},"outputId":"2324615c-000e-47dd-ae0a-700e200578ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["0\n"]}],"source":["random_action = env.action_space.sample()\n","print(random_action)"]},{"cell_type":"markdown","metadata":{"id":"mns-bO01g0-J"},"source":["More, we can utilize `step()` to make agent act according to the randomly-selected `random_action`.\n","The `step()` function will return four values:\n","- observation / state\n","- reward\n","- done (True/ False)\n","- Other information"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E_WViSxGgIk9"},"outputs":[],"source":["observation, reward, done, info = env.step(random_action)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yK7r126kuCNp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657821916269,"user_tz":-480,"elapsed":5,"user":{"displayName":"熾炎使者","userId":"06511828832705263711"}},"outputId":"7890d7de-1fc2-458a-a2a4-2fbcfa26bb50"},"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}],"source":["print(done)"]},{"cell_type":"markdown","metadata":{"id":"GKdS8vOihxhc"},"source":["### Reward\n","\n","\n","> Landing pad is always at coordinates (0,0). Coordinates are the first two numbers in state vector. Reward for moving from the top of the screen to landing pad and zero speed is about 100..140 points. If lander moves away from landing pad it loses reward back. Episode finishes if the lander crashes or comes to rest, receiving additional -100 or +100 points. Each leg ground contact is +10. Firing main engine is -0.3 points each frame. Solved is 200 points. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vxQNs77hi0_7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657821916648,"user_tz":-480,"elapsed":9,"user":{"displayName":"熾炎使者","userId":"06511828832705263711"}},"outputId":"34d6de43-dc8e-4073-9c66-0005cb0f55c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["-0.8588900517154912\n"]}],"source":["print(reward)"]},{"cell_type":"markdown","metadata":{"id":"Mhqp6D-XgHpe"},"source":["### Random Agent\n","In the end, before we start training, we can see whether a random agent can successfully land the moon or not."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y3G0bxoccelv","colab":{"base_uri":"https://localhost:8080/","height":269},"executionInfo":{"status":"ok","timestamp":1657821936784,"user_tz":-480,"elapsed":20141,"user":{"displayName":"熾炎使者","userId":"06511828832705263711"}},"outputId":"6e553121-ae15-43a5-de94-831cce4a0e50"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["env.reset()\n","\n","img = plt.imshow(env.render(mode='rgb_array'))\n","\n","done = False\n","while not done:\n","    action = env.action_space.sample()\n","    observation, reward, done, _ = env.step(action)\n","\n","    img.set_data(env.render(mode='rgb_array'))\n","    display.display(plt.gcf())\n","    display.clear_output(wait=True)"]},{"cell_type":"markdown","metadata":{"id":"RLrveU1mmFpY"},"source":["## Hyper Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qwz9RfOrmIch"},"outputs":[],"source":["BUFFER_SIZE = int(1e5)  # replay buffer size\n","BATCH_SIZE = 256  # 128   # minibatch size\n","GAMMA = 0.99            # discount factor\n","TAU = 1e-3              # for soft update of target parameters\n","LR = 5e-4             # learning rate \n","UPDATE_EVERY = 4  # 4   # how often to update the network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k6i8KAuloOOy"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"F5paWqo7tWL2"},"source":["## Policy Gradient\n","Now, we can build a simple policy network. The network will return one of action in the action space."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J8tdmeD-tZew"},"outputs":[],"source":["# class PolicyGradientNetwork(nn.Module):\n","\n","#     def __init__(self):\n","#         super().__init__()\n","#         self.fc1 = nn.Linear(8, 16)\n","#         self.fc2 = nn.Linear(16, 16)\n","#         self.fc3 = nn.Linear(16, 4)\n","\n","#     def forward(self, state):\n","#         hid = torch.tanh(self.fc1(state))\n","#         hid = torch.tanh(self.fc2(hid))\n","#         return F.softmax(self.fc3(hid), dim=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kRDrXsZ0h5UK"},"outputs":[],"source":["class DQN(nn.Module):\n","    def __init__(self, state_size, action_size):\n","        super(DQN, self).__init__()\n","        self.fc1 = nn.Linear(state_size, 64)\n","        self.fc2 = nn.Linear(64, 64)\n","        self.fc3 = nn.Linear(64, action_size)\n","\n","    def forward(self, state):\n","        x = F.relu(self.fc1(state))\n","        x = F.relu(self.fc2(x))\n","        return self.fc3(x)"]},{"cell_type":"markdown","metadata":{"id":"ynbqJrhIFTC3"},"source":["Then, we need to build a simple agent. The agent will acts according to the output of the policy network above. There are a few things can be done by agent:\n","- `learn()`：update the policy network from log probabilities and rewards.\n","- `sample()`：After receiving observation from the environment, utilize policy network to tell which action to take. The return values of this function includes action and log probabilities. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MTF6ozR0ilb_"},"outputs":[],"source":["class DQNAgent():\n","    \"\"\"Interacts with and learns from the environment.\"\"\"\n","\n","    def __init__(self, state_size, action_size):\n","        \"\"\"Initialize an Agent object.\n","        \n","        Params\n","        ======\n","            state_size (int): dimension of each state\n","            action_size (int): dimension of each action\n","        \"\"\"\n","        self.state_size = state_size\n","        self.action_size = action_size\n","\n","        # Q-Network\n","        self.qnetwork_local = DQN(state_size, action_size).to(device)\n","        self.qnetwork_target = DQN(state_size, action_size).to(device)\n","        # optimizer\n","        # self.optimizer = optim.RMSprop(self.qnetwork_local.parameters(), lr=1e-4)\n","        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n","\n","        # Replay memory\n","        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE)\n","        # Initialize time step (for updating every UPDATE_EVERY steps)\n","        self.t_step = 0\n","    \n","    def step(self, state, action, reward, next_state, done):\n","        # Save experience in replay memory\n","        self.memory.add(state, action, reward, next_state, done)\n","        \n","        # Learn every UPDATE_EVERY time steps.\n","        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n","        if self.t_step == 0:\n","            # If enough samples are available in memory, get random subset and learn\n","            if len(self.memory) > BATCH_SIZE:\n","                experiences = self.memory.sample()\n","                self.learn(experiences, GAMMA)\n","\n","    def act(self, state, eps=0.):\n","        \"\"\"Returns actions for given state as per current policy.\n","        \n","        Params\n","        ======\n","            state (array_like): current state\n","            eps (float): epsilon, for epsilon-greedy action selection\n","        \"\"\"\n","        state = torch.from_numpy(state).float().unsqueeze(0)\n","        self.qnetwork_local.eval()\n","        with torch.no_grad():\n","            action_values = self.qnetwork_local(state)\n","        self.qnetwork_local.train()\n","\n","        # Epsilon-greedy action selection\n","        if random.random() > eps:\n","            return np.argmax(action_values.cpu().data.numpy())\n","        else:\n","            return random.choice(np.arange(self.action_size))\n","\n","    def learn(self, experiences, gamma):\n","        \"\"\"Update value parameters using given batch of experience tuples.\n","\n","        Params\n","        ======\n","            experiences (Tuple[torch.Variable]): tuple of (s, a, r, s', done) tuples \n","            gamma (float): discount factor\n","        \"\"\"\n","        # Obtain random minibatch of tuples from D\n","        states, actions, rewards, next_states, dones = experiences\n","\n","        ## Compute and minimize the loss\n","        ### Extract next maximum estimated value from target network\n","        q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n","        ### Calculate target value from bellman equation\n","        q_targets = rewards + gamma * q_targets_next * (1 - dones)\n","        ### Calculate expected value from local network\n","        q_expected = self.qnetwork_local(states).gather(1, actions)\n","        \n","        ### Loss calculation (we used Mean squared error)\n","        loss = F.mse_loss(q_expected, q_targets)\n","        self.optimizer.zero_grad()\n","        loss.backward()\n","        self.optimizer.step()\n","\n","        # ------------------- update target network ------------------- #\n","        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)                     \n","\n","    def soft_update(self, local_model, target_model, tau):\n","        \"\"\"Soft update model parameters.\n","        θ_target = τ*θ_local + (1 - τ)*θ_target\n","\n","        Params\n","        ======\n","            local_model (PyTorch model): weights will be copied from\n","            target_model (PyTorch model): weights will be copied to\n","            tau (float): interpolation parameter \n","        \"\"\"\n","        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n","            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Q6CZ7i1j7dy"},"outputs":[],"source":["class ReplayBuffer:\n","    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n","\n","    def __init__(self, action_size, buffer_size, batch_size):\n","        \"\"\"Initialize a ReplayBuffer object.\n","\n","        Params\n","        ======\n","            action_size (int): dimension of each action\n","            buffer_size (int): maximum size of buffer\n","            batch_size (int): size of each training batch\n","        \"\"\"\n","        self.action_size = action_size\n","        self.memory = deque(maxlen=buffer_size)  \n","        self.batch_size = batch_size\n","        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n","    \n","    def add(self, state, action, reward, next_state, done):\n","        \"\"\"Add a new experience to memory.\"\"\"\n","        e = self.experience(state, action, reward, next_state, done)\n","        self.memory.append(e)\n","    \n","    def sample(self):\n","        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n","        experiences = random.sample(self.memory, k=self.batch_size)\n","\n","        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n","        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n","        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n","        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n","        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n","  \n","        return (states, actions, rewards, next_states, dones)\n","\n","    def __len__(self):\n","        \"\"\"Return the current size of internal memory.\"\"\"\n","        return len(self.memory)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZo-IxJx286z"},"outputs":[],"source":["# from torch.optim.lr_scheduler import StepLR\n","# class PolicyGradientAgent():\n","    \n","#     def __init__(self, network):\n","#         self.network = network\n","#         self.optimizer = optim.SGD(self.network.parameters(), lr=0.001)\n","        \n","#     def forward(self, state):\n","#         return self.network(state)\n","\n","#     def learn(self, log_probs, rewards):\n","#         loss = (-log_probs * rewards).sum() # You don't need to revise this to pass simple baseline (but you can)\n","\n","#         self.optimizer.zero_grad()\n","#         loss.backward()\n","#         self.optimizer.step()\n","        \n","#     def sample(self, state):\n","#         action_prob = self.network(torch.FloatTensor(state))\n","#         action_dist = Categorical(action_prob)\n","#         action = action_dist.sample()\n","#         log_prob = action_dist.log_prob(action)\n","#         return action.item(), log_prob"]},{"cell_type":"markdown","metadata":{"id":"ehPlnTKyRZf9"},"source":["Lastly, build a network and agent to start training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GfJIvML-RYjL"},"outputs":[],"source":["# network = PolicyGradientNetwork()\n","# agent = PolicyGradientAgent(network)"]},{"cell_type":"markdown","metadata":{"id":"ouv23glgf5Qt"},"source":["## Training Agent\n","\n","Now let's start to train our agent.\n","Through taking all the interactions between agent and environment as training data, the policy network can learn from all these attempts,"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EtGWgE91kFWV"},"outputs":[],"source":["def training(n_episodes=3000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n","    \"\"\"Deep Q-Learning.\n","    \n","    Params\n","    ======\n","        n_episodes (int): maximum number of training episodes\n","        max_t (int): maximum number of timesteps per episode\n","        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n","        eps_end (float): minimum value of epsilon\n","        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n","    \"\"\"\n","    scores = []                        # list containing scores from each episode\n","    scores_window = deque(maxlen=100)  # last 100 scores\n","    eps = eps_start                    # initialize epsilon\n","    for i_episode in range(1, n_episodes+1):\n","        state = env.reset()\n","        score = 0\n","        for t in range(max_t):\n","            action = agent.act(state, eps)\n","            next_state, reward, done, _ = env.step(action)\n","            agent.step(state, action, reward, next_state, done)\n","            state = next_state\n","            score += reward\n","            if done:\n","                break \n","        scores_window.append(score)       # save most recent score\n","        scores.append(score)              # save most recent score\n","        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n","        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n","        if i_episode % 100 == 0:\n","            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n","        if np.mean(scores_window) >= 270:  # 270\n","            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n","            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n","            break\n","    return scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7zIyBu_HkHcL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657824688273,"user_tz":-480,"elapsed":2750954,"user":{"displayName":"熾炎使者","userId":"06511828832705263711"}},"outputId":"84a5e900-523e-4b52-d59d-318a7cd201af"},"outputs":[{"output_type":"stream","name":"stdout","text":["Episode 100\tAverage Score: -162.95\n","Episode 200\tAverage Score: -106.48\n","Episode 300\tAverage Score: -26.63\n","Episode 400\tAverage Score: 46.97\n","Episode 500\tAverage Score: 145.34\n","Episode 600\tAverage Score: 178.43\n","Episode 700\tAverage Score: 189.28\n","Episode 800\tAverage Score: 167.68\n","Episode 900\tAverage Score: 196.67\n","Episode 1000\tAverage Score: 213.71\n","Episode 1100\tAverage Score: 233.66\n","Episode 1200\tAverage Score: 230.15\n","Episode 1300\tAverage Score: 237.92\n","Episode 1400\tAverage Score: 235.18\n","Episode 1500\tAverage Score: 240.80\n","Episode 1600\tAverage Score: 236.68\n","Episode 1700\tAverage Score: 250.18\n","Episode 1800\tAverage Score: 239.49\n","Episode 1900\tAverage Score: 256.29\n","Episode 2000\tAverage Score: 241.09\n","Episode 2100\tAverage Score: 242.21\n","Episode 2200\tAverage Score: 251.16\n","Episode 2300\tAverage Score: 244.95\n","Episode 2400\tAverage Score: 248.90\n","Episode 2500\tAverage Score: 237.40\n","Episode 2600\tAverage Score: 239.00\n","Episode 2700\tAverage Score: 246.11\n","Episode 2800\tAverage Score: 258.58\n","Episode 2900\tAverage Score: 257.98\n","Episode 3000\tAverage Score: 260.76\n"]}],"source":["agent = DQNAgent(state_size=8, action_size=4)\n","scores = training()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vg5rxBBaf38_"},"outputs":[],"source":["# agent.network.train()  # Switch network into training mode \n","# EPISODE_PER_BATCH = 5  # update the  agent every 5 episode\n","# NUM_BATCH = 500        # totally update the agent for 400 time\n","\n","# avg_total_rewards, avg_final_rewards = [], []\n","\n","# prg_bar = tqdm(range(NUM_BATCH))\n","# for batch in prg_bar:\n","\n","#     log_probs, rewards = [], []\n","#     total_rewards, final_rewards = [], []\n","\n","#     # collect trajectory\n","#     for episode in range(EPISODE_PER_BATCH):\n","        \n","#         state = env.reset()\n","#         total_reward, total_step = 0, 0\n","#         seq_rewards = []\n","#         while True:\n","\n","#             action, log_prob = agent.sample(state) # at, log(at|st)\n","#             next_state, reward, done, _ = env.step(action)\n","\n","#             log_probs.append(log_prob) # [log(a1|s1), log(a2|s2), ...., log(at|st)]\n","#             # seq_rewards.append(reward)\n","#             state = next_state\n","#             total_reward += reward\n","#             total_step += 1\n","#             rewards.append(reward) # change here\n","#             # ! IMPORTANT !\n","#             # Current reward implementation: immediate reward,  given action_list : a1, a2, a3 ......\n","#             #                                                         rewards :     r1, r2 ,r3 ......\n","#             # medium：change \"rewards\" to accumulative decaying reward, given action_list : a1,                           a2,                           a3, ......\n","#             #                                                           rewards :           r1+0.99*r2+0.99^2*r3+......, r2+0.99*r3+0.99^2*r4+...... ,  r3+0.99*r4+0.99^2*r5+ ......\n","#             # boss : implement Actor-Critic\n","#             if done:\n","#                 final_rewards.append(reward)\n","#                 total_rewards.append(total_reward)\n","                \n","#                 break\n","\n","#     # print(f\"rewards looks like \", np.shape(rewards))  \n","#     # print(f\"log_probs looks like \", np.shape(log_probs))     \n","#     # record training process\n","#     avg_total_reward = sum(total_rewards) / len(total_rewards)\n","#     avg_final_reward = sum(final_rewards) / len(final_rewards)\n","#     avg_total_rewards.append(avg_total_reward)\n","#     avg_final_rewards.append(avg_final_reward)\n","#     prg_bar.set_description(f\"Total: {avg_total_reward: 4.1f}, Final: {avg_final_reward: 4.1f}\")\n","\n","#     # update agent\n","#     # rewards = np.concatenate(rewards, axis=0)\n","#     rewards = (rewards - np.mean(rewards)) / (np.std(rewards) + 1e-9)  # normalize the reward \n","#     agent.learn(torch.stack(log_probs), torch.from_numpy(rewards))\n","#     print(\"logs prob looks like \", torch.stack(log_probs).size())\n","#     print(\"torch.from_numpy(rewards) looks like \", torch.from_numpy(rewards).size())"]},{"cell_type":"markdown","metadata":{"id":"vNb_tuFYhKVK"},"source":["### Training Result\n","During the training process, we recorded `avg_total_reward`, which represents the average total reward of episodes before updating the policy network.\n","\n","Theoretically, if the agent becomes better, the `avg_total_reward` will increase.\n","The visualization of the training process is shown below:  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZYOI8H10SHN","colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"status":"ok","timestamp":1657824688956,"user_tz":-480,"elapsed":685,"user":{"displayName":"熾炎使者","userId":"06511828832705263711"}},"outputId":"62f81441-78c3-4fe2-ff1d-380846a6f14a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["plt.plot(scores)\n","plt.title(\"Total Rewards\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"mV5jj4dThz0Y"},"source":["In addition, `avg_final_reward` represents average final rewards of episodes. To be specific, final rewards is the last reward received in one episode, indicating whether the craft lands successfully or not.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"txDZ5vlGWz5w"},"outputs":[],"source":["# plt.plot(avg_final_rewards)\n","# plt.title(\"Final Rewards\")\n","# plt.show()"]},{"cell_type":"markdown","metadata":{"id":"u2HaGRVEYGQS"},"source":["## Testing\n","The testing result will be the average reward of 5 testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5yFuUKKRYH73","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bbbf0bbe-c801-44de-ce9c-26d038f7e6c9"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/__init__.py:422: UserWarning: torch.set_deterministic is deprecated and will be removed in a future release. Please use torch.use_deterministic_algorithms instead\n","  \"torch.set_deterministic is deprecated and will be removed in a future \"\n"]}],"source":["fix(env, seed)\n","agent.qnetwork_local.eval()\n","agent.qnetwork_target.eval()\n","NUM_OF_TEST = 5 # Do not revise this !!!\n","test_total_reward = []\n","action_list = []\n","\n","for i in range(NUM_OF_TEST):\n","  actions = []\n","  state = env.reset()\n","\n","  img = plt.imshow(env.render(mode='rgb_array'))\n","\n","  total_reward = 0\n","\n","  done = False\n","\n","  while not done:\n","\n","      action = agent.act(state)\n","      actions.append(action)\n","      state, reward, done, _ = env.step(action)\n","\n","      total_reward += reward\n","\n","      # img.set_data(env.render(mode='rgb_array'))\n","      # display.display(plt.gcf())\n","      # display.clear_output(wait=True)\n","      \n","  print(total_reward)\n","  test_total_reward.append(total_reward)\n","\n","  action_list.append(actions) # save the result of testing \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aex7mcKr0J01","colab":{"base_uri":"https://localhost:8080/","height":168},"executionInfo":{"status":"error","timestamp":1657824910245,"user_tz":-480,"elapsed":354,"user":{"displayName":"熾炎使者","userId":"06511828832705263711"}},"outputId":"1764fabd-feee-4633-a621-fa701f364a92"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-503d6e85363e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Your final reward is : %.2f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_total_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}],"source":["print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))"]},{"cell_type":"markdown","metadata":{"id":"leyebGYRpqsF"},"source":["Action list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hGAH4YWDpp4u"},"outputs":[],"source":["print(\"Action list looks like \", action_list)\n","print(\"Action list's shape looks like \", np.shape(action_list))"]},{"cell_type":"markdown","metadata":{"id":"fNkmwucrHMen"},"source":["Analysis of actions taken by agent"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WHdAItjj1nxw"},"outputs":[],"source":["distribution = {}\n","for actions in action_list:\n","  for action in actions:\n","    if action not in distribution.keys():\n","      distribution[action] = 1\n","    else:\n","      distribution[action] += 1\n","print(distribution)"]},{"cell_type":"markdown","metadata":{"id":"ricE0schY75M"},"source":["Saving the result of Model Testing\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GZsMkGmIY42b"},"outputs":[],"source":["PATH = \"Action_List.npy\" # Can be modified into the name or path you want\n","np.save(PATH ,np.array(action_list)) "]},{"cell_type":"markdown","metadata":{"id":"asK7WfbkaLjt"},"source":["### This is the file you need to submit !!!\n","Download the testing result to your device\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c-CqyhHzaWAL"},"outputs":[],"source":["from google.colab import files\n","files.download(PATH)"]},{"cell_type":"markdown","metadata":{"id":"seT4NUmWmAZ1"},"source":["# Server \n","The code below simulate the environment on the judge server. Can be used for testing."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U69c-YTxaw6b"},"outputs":[],"source":["action_list = np.load(PATH,allow_pickle=True) # The action list you upload\n","seed = 543 # Do not revise this\n","fix(env, seed)\n","\n","# set network to evaluation mode\n","agent.qnetwork_local.eval()\n","agent.qnetwork_target.eval()\n","\n","test_total_reward = []\n","if len(action_list) != 5:\n","  print(\"Wrong format of file !!!\")\n","  exit(0)\n","for actions in action_list:\n","  state = env.reset()\n","  img = plt.imshow(env.render(mode='rgb_array'))\n","\n","  total_reward = 0\n","\n","  done = False\n","\n","  for action in actions:\n","  \n","      state, reward, done, _ = env.step(action)\n","      total_reward += reward\n","      if done:\n","        break\n","\n","  print(f\"Your reward is : %.2f\"%total_reward)\n","  test_total_reward.append(total_reward)"]},{"cell_type":"markdown","metadata":{"id":"TjFBWwQP1hVe"},"source":["# Your score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GpJpZz3Wbm0X"},"outputs":[],"source":["print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))"]},{"cell_type":"markdown","metadata":{"id":"wUBtYXG2eaqf"},"source":["## Reference\n","\n","Below are some useful tips for you to get high score.\n","\n","- [DRL Lecture 1: Policy Gradient (Review)](https://youtu.be/z95ZYgPgXOY)\n","- [ML Lecture 23-3: Reinforcement Learning (including Q-learning) start at 30:00](https://youtu.be/2-JNBzCq77c?t=1800)\n","- [Lecture 7: Policy Gradient, David Silver](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/pg.pdf)\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"12. hw12_strong.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}