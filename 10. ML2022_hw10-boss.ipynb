{"cells":[{"cell_type":"markdown","metadata":{"id":"Q-n2e0BkhEKS"},"source":["# **Homework 10 - Adversarial Attack**\n","\n","Slides: https://reurl.cc/7DDxnD\n","\n","Contact: ntu-ml-2022spring-ta@googlegroups.com\n"]},{"cell_type":"markdown","metadata":{"id":"9RX7iRXrhMA_"},"source":["## Enviroment & Download\n","\n","We make use of [pytorchcv](https://pypi.org/project/pytorchcv/) to obtain CIFAR-10 pretrained model, so we need to set up the enviroment first. We also need to download the data (200 images) which we want to attack."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4Lw7urignqP","outputId":"3d716612-698a-4490-da86-c6597d74a141","executionInfo":{"status":"ok","timestamp":1657028940349,"user_tz":-480,"elapsed":14727,"user":{"displayName":"天","userId":"11778751613550389138"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorchcv\n","  Downloading pytorchcv-0.0.67-py2.py3-none-any.whl (532 kB)\n","\u001b[K     |████████████████████████████████| 532 kB 31.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorchcv) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorchcv) (1.21.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorchcv) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorchcv) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorchcv) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorchcv) (2.10)\n","Installing collected packages: pytorchcv\n","Successfully installed pytorchcv-0.0.67\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (0.2.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.15.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.4.1)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.8.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug) (7.1.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug) (3.2.2)\n","Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug) (0.18.3)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug) (4.1.2.30)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug) (2.4.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug) (2.6.3)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug) (1.3.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug) (2021.11.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (1.4.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug) (4.1.1)\n","--2022-07-05 13:48:57--  https://github.com/DanielLin94144/ML-attack-dataset/files/8167812/data.zip\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-repository-file-5c1aeb/465178219/8167812?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220705%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220705T134858Z&X-Amz-Expires=300&X-Amz-Signature=00dca52a0e517d5c63ce8eff3fd23757497387d08b03d22be4d72a3e54c870da&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=465178219&response-content-disposition=attachment%3Bfilename%3Ddata.zip&response-content-type=application%2Fzip [following]\n","--2022-07-05 13:48:58--  https://objects.githubusercontent.com/github-production-repository-file-5c1aeb/465178219/8167812?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220705%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220705T134858Z&X-Amz-Expires=300&X-Amz-Signature=00dca52a0e517d5c63ce8eff3fd23757497387d08b03d22be4d72a3e54c870da&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=465178219&response-content-disposition=attachment%3Bfilename%3Ddata.zip&response-content-type=application%2Fzip\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 489509 (478K) [application/zip]\n","Saving to: ‘data.zip’\n","\n","data.zip            100%[===================>] 478.04K   390KB/s    in 1.2s    \n","\n","2022-07-05 13:49:00 (390 KB/s) - ‘data.zip’ saved [489509/489509]\n","\n","Archive:  ./data.zip\n","   creating: data/\n","   creating: data/deer/\n"," extracting: data/deer/deer13.png    \n"," extracting: data/deer/deer6.png     \n"," extracting: data/deer/deer11.png    \n"," extracting: data/deer/deer2.png     \n"," extracting: data/deer/deer10.png    \n"," extracting: data/deer/deer16.png    \n"," extracting: data/deer/deer9.png     \n"," extracting: data/deer/deer20.png    \n"," extracting: data/deer/deer15.png    \n"," extracting: data/deer/deer19.png    \n"," extracting: data/deer/deer5.png     \n"," extracting: data/deer/deer14.png    \n"," extracting: data/deer/deer4.png     \n"," extracting: data/deer/deer8.png     \n"," extracting: data/deer/deer12.png    \n"," extracting: data/deer/deer1.png     \n"," extracting: data/deer/deer7.png     \n"," extracting: data/deer/deer17.png    \n"," extracting: data/deer/deer18.png    \n"," extracting: data/deer/deer3.png     \n","   creating: data/horse/\n"," extracting: data/horse/horse9.png   \n"," extracting: data/horse/horse1.png   \n"," extracting: data/horse/horse16.png  \n"," extracting: data/horse/horse15.png  \n"," extracting: data/horse/horse19.png  \n"," extracting: data/horse/horse14.png  \n"," extracting: data/horse/horse10.png  \n"," extracting: data/horse/horse7.png   \n"," extracting: data/horse/horse2.png   \n"," extracting: data/horse/horse6.png   \n"," extracting: data/horse/horse20.png  \n"," extracting: data/horse/horse5.png   \n"," extracting: data/horse/horse18.png  \n"," extracting: data/horse/horse12.png  \n"," extracting: data/horse/horse13.png  \n"," extracting: data/horse/horse17.png  \n"," extracting: data/horse/horse4.png   \n"," extracting: data/horse/horse11.png  \n"," extracting: data/horse/horse8.png   \n"," extracting: data/horse/horse3.png   \n","   creating: data/ship/\n"," extracting: data/ship/ship10.png    \n"," extracting: data/ship/ship14.png    \n"," extracting: data/ship/ship9.png     \n"," extracting: data/ship/ship20.png    \n"," extracting: data/ship/ship5.png     \n"," extracting: data/ship/ship8.png     \n"," extracting: data/ship/ship19.png    \n"," extracting: data/ship/ship16.png    \n"," extracting: data/ship/ship13.png    \n"," extracting: data/ship/ship6.png     \n"," extracting: data/ship/ship17.png    \n"," extracting: data/ship/ship1.png     \n"," extracting: data/ship/ship12.png    \n"," extracting: data/ship/ship2.png     \n"," extracting: data/ship/ship3.png     \n"," extracting: data/ship/ship15.png    \n"," extracting: data/ship/ship4.png     \n"," extracting: data/ship/ship7.png     \n"," extracting: data/ship/ship11.png    \n"," extracting: data/ship/ship18.png    \n","   creating: data/frog/\n"," extracting: data/frog/frog10.png    \n"," extracting: data/frog/frog4.png     \n"," extracting: data/frog/frog5.png     \n"," extracting: data/frog/frog20.png    \n"," extracting: data/frog/frog15.png    \n"," extracting: data/frog/frog3.png     \n"," extracting: data/frog/frog1.png     \n"," extracting: data/frog/frog14.png    \n"," extracting: data/frog/frog2.png     \n"," extracting: data/frog/frog19.png    \n"," extracting: data/frog/frog7.png     \n"," extracting: data/frog/frog11.png    \n"," extracting: data/frog/frog17.png    \n"," extracting: data/frog/frog18.png    \n"," extracting: data/frog/frog12.png    \n"," extracting: data/frog/frog16.png    \n"," extracting: data/frog/frog8.png     \n"," extracting: data/frog/frog13.png    \n"," extracting: data/frog/frog6.png     \n"," extracting: data/frog/frog9.png     \n","   creating: data/airplane/\n"," extracting: data/airplane/airplane3.png  \n"," extracting: data/airplane/airplane4.png  \n"," extracting: data/airplane/airplane2.png  \n"," extracting: data/airplane/airplane9.png  \n"," extracting: data/airplane/airplane20.png  \n"," extracting: data/airplane/airplane18.png  \n"," extracting: data/airplane/airplane19.png  \n"," extracting: data/airplane/airplane10.png  \n"," extracting: data/airplane/airplane6.png  \n"," extracting: data/airplane/airplane13.png  \n"," extracting: data/airplane/airplane16.png  \n"," extracting: data/airplane/airplane14.png  \n"," extracting: data/airplane/airplane11.png  \n"," extracting: data/airplane/airplane1.png  \n"," extracting: data/airplane/airplane17.png  \n"," extracting: data/airplane/airplane7.png  \n"," extracting: data/airplane/airplane15.png  \n"," extracting: data/airplane/airplane5.png  \n"," extracting: data/airplane/airplane8.png  \n"," extracting: data/airplane/airplane12.png  \n","   creating: data/bird/\n"," extracting: data/bird/bird9.png     \n"," extracting: data/bird/bird12.png    \n"," extracting: data/bird/bird10.png    \n"," extracting: data/bird/bird11.png    \n"," extracting: data/bird/bird5.png     \n"," extracting: data/bird/bird8.png     \n"," extracting: data/bird/bird4.png     \n"," extracting: data/bird/bird3.png     \n"," extracting: data/bird/bird7.png     \n"," extracting: data/bird/bird18.png    \n"," extracting: data/bird/bird14.png    \n"," extracting: data/bird/bird13.png    \n"," extracting: data/bird/bird2.png     \n"," extracting: data/bird/bird15.png    \n"," extracting: data/bird/bird17.png    \n"," extracting: data/bird/bird19.png    \n"," extracting: data/bird/bird16.png    \n"," extracting: data/bird/bird6.png     \n"," extracting: data/bird/bird20.png    \n"," extracting: data/bird/bird1.png     \n","   creating: data/cat/\n"," extracting: data/cat/cat6.png       \n"," extracting: data/cat/cat1.png       \n"," extracting: data/cat/cat7.png       \n"," extracting: data/cat/cat19.png      \n"," extracting: data/cat/cat5.png       \n"," extracting: data/cat/cat9.png       \n"," extracting: data/cat/cat17.png      \n"," extracting: data/cat/cat2.png       \n"," extracting: data/cat/cat16.png      \n"," extracting: data/cat/cat10.png      \n"," extracting: data/cat/cat4.png       \n"," extracting: data/cat/cat18.png      \n"," extracting: data/cat/cat13.png      \n"," extracting: data/cat/cat11.png      \n"," extracting: data/cat/cat20.png      \n"," extracting: data/cat/cat15.png      \n"," extracting: data/cat/cat8.png       \n"," extracting: data/cat/cat14.png      \n"," extracting: data/cat/cat3.png       \n"," extracting: data/cat/cat12.png      \n","   creating: data/automobile/\n"," extracting: data/automobile/automobile17.png  \n"," extracting: data/automobile/automobile11.png  \n"," extracting: data/automobile/automobile5.png  \n"," extracting: data/automobile/automobile10.png  \n"," extracting: data/automobile/automobile20.png  \n"," extracting: data/automobile/automobile2.png  \n"," extracting: data/automobile/automobile6.png  \n"," extracting: data/automobile/automobile1.png  \n"," extracting: data/automobile/automobile19.png  \n"," extracting: data/automobile/automobile7.png  \n"," extracting: data/automobile/automobile16.png  \n"," extracting: data/automobile/automobile3.png  \n"," extracting: data/automobile/automobile14.png  \n"," extracting: data/automobile/automobile12.png  \n"," extracting: data/automobile/automobile9.png  \n"," extracting: data/automobile/automobile4.png  \n"," extracting: data/automobile/automobile8.png  \n"," extracting: data/automobile/automobile13.png  \n"," extracting: data/automobile/automobile18.png  \n"," extracting: data/automobile/automobile15.png  \n","   creating: data/dog/\n"," extracting: data/dog/dog9.png       \n"," extracting: data/dog/dog2.png       \n"," extracting: data/dog/dog15.png      \n"," extracting: data/dog/dog8.png       \n"," extracting: data/dog/dog3.png       \n"," extracting: data/dog/dog19.png      \n"," extracting: data/dog/dog12.png      \n"," extracting: data/dog/dog7.png       \n"," extracting: data/dog/dog17.png      \n"," extracting: data/dog/dog11.png      \n"," extracting: data/dog/dog16.png      \n"," extracting: data/dog/dog20.png      \n"," extracting: data/dog/dog4.png       \n"," extracting: data/dog/dog5.png       \n"," extracting: data/dog/dog14.png      \n"," extracting: data/dog/dog18.png      \n"," extracting: data/dog/dog10.png      \n"," extracting: data/dog/dog1.png       \n"," extracting: data/dog/dog13.png      \n"," extracting: data/dog/dog6.png       \n","   creating: data/truck/\n"," extracting: data/truck/truck1.png   \n"," extracting: data/truck/truck18.png  \n"," extracting: data/truck/truck9.png   \n"," extracting: data/truck/truck4.png   \n"," extracting: data/truck/truck14.png  \n"," extracting: data/truck/truck8.png   \n"," extracting: data/truck/truck12.png  \n"," extracting: data/truck/truck15.png  \n"," extracting: data/truck/truck2.png   \n"," extracting: data/truck/truck5.png   \n"," extracting: data/truck/truck3.png   \n"," extracting: data/truck/truck10.png  \n"," extracting: data/truck/truck17.png  \n"," extracting: data/truck/truck20.png  \n"," extracting: data/truck/truck19.png  \n"," extracting: data/truck/truck13.png  \n"," extracting: data/truck/truck7.png   \n"," extracting: data/truck/truck6.png   \n","  inflating: data/truck/truck16.png  \n"," extracting: data/truck/truck11.png  \n"]}],"source":["# set up environment\n","!pip install pytorchcv\n","!pip install imgaug\n","\n","# download\n","!wget https://github.com/DanielLin94144/ML-attack-dataset/files/8167812/data.zip\n","#\n","## unzip\n","!unzip ./data.zip\n","!rm ./data.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5inbFx_alYjw"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","batch_size = 8"]},{"cell_type":"markdown","metadata":{"id":"hkQQf0l1hbBs"},"source":["## Global Settings \n","#### **[NOTE]**: Don't change the settings here, or your generated image might not meet the constraint.\n","* $\\epsilon$ is fixed to be 8. But on **Data section**, we will first apply transforms on raw pixel value (0-255 scale) **by ToTensor (to 0-1 scale)** and then **Normalize (subtract mean divide std)**. $\\epsilon$ should be set to $\\frac{8}{255 * std}$ during attack.\n","\n","* Explaination (optional)\n","    * Denote the first pixel of original image as $p$, and the first pixel of adversarial image as $a$.\n","    * The $\\epsilon$ constraints tell us $\\left| p-a \\right| <= 8$.\n","    * ToTensor() can be seen as a function where $T(x) = x/255$.\n","    * Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n","    * After applying ToTensor() and Normalize() on $p$ and $a$, the constraint becomes $\\left| N(T(p))-N(T(a)) \\right| = \\left| \\frac{\\frac{p}{255}-mean}{std}-\\frac{\\frac{a}{255}-mean}{std} \\right| = \\frac{1}{255 * std} \\left| p-a \\right| <= \\frac{8}{255 * std}.$\n","    * So, we should set $\\epsilon$ to be $\\frac{8}{255 * std}$ after ToTensor() and Normalize()."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ACghc_tsg2vE"},"outputs":[],"source":["# the mean and std are the calculated statistics from cifar_10 dataset\n","cifar_10_mean = (0.491, 0.482, 0.447) # mean for the three channels of cifar_10 images\n","cifar_10_std = (0.202, 0.199, 0.201) # std for the three channels of cifar_10 images\n","\n","# convert mean and std to 3-dimensional tensors for future operations\n","mean = torch.tensor(cifar_10_mean).to(device).view(3, 1, 1)\n","std = torch.tensor(cifar_10_std).to(device).view(3, 1, 1)\n","\n","epsilon = 8/255/std"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uO8f0NmtlM63"},"outputs":[],"source":["root = './data' # directory for storing benign images\n","# benign images: images which do not contain adversarial perturbations\n","# adversarial images: images which include adversarial perturbations"]},{"cell_type":"markdown","metadata":{"id":"lhBJBAlKherZ"},"source":["## Data\n","\n","Construct dataset and dataloader from root directory. Note that we store the filename of each image for future usage."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VXpRAHz0hkDt","outputId":"168f1af5-a34e-4f1e-b8af-82aa39c0fd0e","executionInfo":{"status":"ok","timestamp":1657028957618,"user_tz":-480,"elapsed":15,"user":{"displayName":"天","userId":"11778751613550389138"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["number of images = 200\n"]}],"source":["import os\n","import glob\n","import shutil\n","import numpy as np\n","from PIL import Image\n","from torchvision.transforms import transforms\n","from torch.utils.data import Dataset, DataLoader\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(cifar_10_mean, cifar_10_std)\n","])\n","\n","class AdvDataset(Dataset):\n","    def __init__(self, data_dir, transform):\n","        self.images = []\n","        self.labels = []\n","        self.names = []\n","        '''\n","        data_dir\n","        ├── class_dir\n","        │   ├── class1.png\n","        │   ├── ...\n","        │   ├── class20.png\n","        '''\n","        for i, class_dir in enumerate(sorted(glob.glob(f'{data_dir}/*'))):\n","            images = sorted(glob.glob(f'{class_dir}/*'))\n","            self.images += images\n","            self.labels += ([i] * len(images))\n","            self.names += [os.path.relpath(imgs, data_dir) for imgs in images]\n","        self.transform = transform\n","    def __getitem__(self, idx):\n","        image = self.transform(Image.open(self.images[idx]))\n","        label = self.labels[idx]\n","        return image, label\n","    def __getname__(self):\n","        return self.names\n","    def __len__(self):\n","        return len(self.images)\n","\n","adv_set = AdvDataset(root, transform=transform)\n","adv_names = adv_set.__getname__()\n","adv_loader = DataLoader(adv_set, batch_size=batch_size, shuffle=False)\n","\n","print(f'number of images = {adv_set.__len__()}')"]},{"cell_type":"markdown","metadata":{"id":"LnszlTsYrTQZ"},"source":["## Utils -- Benign Images Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5c_zZLzkrceE"},"outputs":[],"source":["# to evaluate the performance of model on benign images\n","def epoch_benign(model, loader, loss_fn):\n","    model.eval()\n","    train_acc, train_loss = 0.0, 0.0\n","    for x, y in loader:\n","        x, y = x.to(device), y.to(device)\n","        yp = model(x)\n","        loss = loss_fn(yp, y)\n","        train_acc += (yp.argmax(dim=1) == y).sum().item()\n","        train_loss += loss.item() * x.shape[0]\n","    return train_acc / len(loader.dataset), train_loss / len(loader.dataset)"]},{"cell_type":"markdown","metadata":{"id":"_YJxK7YehqQy"},"source":["## Utils -- Attack Algorithm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F_1wKfKyhrQW"},"outputs":[],"source":["# perform fgsm attack\n","def fgsm(model, x, y, loss_fn, epsilon=epsilon):\n","    x_adv = x.detach().clone() # initialize x_adv as original benign image x\n","    x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n","    loss = loss_fn(model(x_adv), y) # calculate loss\n","    loss.backward() # calculate gradient\n","    # fgsm: use gradient ascent on x_adv to maximize loss\n","    grad = x_adv.grad.detach()\n","    x_adv = x_adv + epsilon * grad.sign()\n","    return x_adv\n","\n","# alpha and num_iter can be decided by yourself\n","alpha = 0.8/255/std\n","def ifgsm(model, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=20):\n","    x_adv = x\n","    # write a loop of num_iter to represent the iterative times\n","    for i in range(num_iter):\n","        # x_adv = fgsm(model, x_adv, y, loss_fn, alpha) # call fgsm with (epsilon = alpha) to obtain new x_adv\n","        x_adv = x_adv.detach().clone()\n","        x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n","        loss = loss_fn(model(x_adv), y) # calculate loss\n","        loss.backward() # calculate gradient\n","        # fgsm: use gradient ascent on x_adv to maximize loss\n","        grad = x_adv.grad.detach()\n","        x_adv = x_adv + alpha * grad.sign()\n","\n","        x_adv = torch.max(torch.min(x_adv, x+epsilon), x-epsilon) # clip new x_adv back to [x-epsilon, x+epsilon]\n","    return x_adv\n","\n","def mifgsm(model, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=20, decay=1.0):\n","    x_adv = x\n","    # initialze momentum tensor\n","    momentum = torch.zeros_like(x).detach().to(device)\n","    # write a loop of num_iter to represent the iterative times\n","    for i in range(num_iter):\n","        x_adv = x_adv.detach().clone()\n","        x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n","        loss = loss_fn(model(x_adv), y) # calculate loss\n","        loss.backward() # calculate gradient\n","        # TODO: Momentum calculation\n","        # grad = .....\n","        grad = x_adv.grad.detach()\n","        grad = decay * momentum + grad/(grad.abs().sum() + 1e-8)\n","        momentum = grad\n","        x_adv = x_adv + alpha * grad.sign()\n","        x_adv = torch.max(torch.min(x_adv, x+epsilon), x-epsilon) # clip new x_adv back to [x-epsilon, x+epsilon]\n","    return x_adv\n","\n","def dmi_mifgsm(model, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=50, decay=1.0, p=0.5):\n","    x_adv = x\n","    # initialze momentum tensor\n","    momentum = torch.zeros_like(x).detach().to(device)\n","    # write a loop of num_iter to represent the iterative times\n","    for i in range(num_iter):\n","        x_adv = x_adv.detach().clone()\n","        x_adv_raw = x_adv.clone()\n","        if torch.rand(1).item() >= p:\n","            #resize img to rnd X rnd\n","            rnd = torch.randint(29, 33, (1,)).item()\n","            x_adv = transforms.Resize((rnd, rnd))(x_adv)\n","            #padding img to 32 X 32 with 0\n","            left = torch.randint(0, 32 - rnd + 1, (1,)).item()\n","            top = torch.randint(0, 32 - rnd + 1, (1,)).item()\n","            right = 32 - rnd - left\n","            bottom = 32 - rnd - top\n","            x_adv = transforms.Pad([left, top, right, bottom])(x_adv)\n","        x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n","        loss = loss_fn(model(x_adv), y) # calculate loss\n","        loss.backward() # calculate gradient\n","        # TODO: Momentum calculation\n","        # grad = .....   \n","        grad = x_adv.grad.detach()\n","        grad = decay * momentum + grad/(grad.abs().sum() + 1e-8)\n","        momentum = grad\n","        x_adv = x_adv_raw + alpha * grad.sign()\n","        x_adv = torch.max(torch.min(x_adv, x+epsilon), x-epsilon) # clip new x_adv back to [x-epsilon, x+epsilon]\n","    return x_adv"]},{"cell_type":"markdown","metadata":{"id":"fYCEQwmcrmH6"},"source":["## Utils -- Attack\n","* Recall\n","  * ToTensor() can be seen as a function where $T(x) = x/255$.\n","  * Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n","\n","* Inverse function\n","  * Inverse Normalize() can be seen as a function where $N^{-1}(x) = x*std+mean$ where $mean$ and $std$ are constants.\n","  * Inverse ToTensor() can be seen as a function where $T^{-1}(x) = x*255$.\n","\n","* Special Noted\n","  * ToTensor() will also convert the image from shape (height, width, channel) to shape (channel, height, width), so we also need to transpose the shape back to original shape.\n","  * Since our dataloader samples a batch of data, what we need here is to transpose **(batch_size, channel, height, width)** back to **(batch_size, height, width, channel)** using np.transpose."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w5X_9x-7ro_w"},"outputs":[],"source":["# perform adversarial attack and generate adversarial examples\n","def gen_adv_examples(model, loader, attack, loss_fn):\n","    model.eval()\n","    adv_names = []\n","    train_acc, train_loss = 0.0, 0.0\n","    for i, (x, y) in enumerate(loader):\n","        x, y = x.to(device), y.to(device)\n","        x_adv = attack(model, x, y, loss_fn) # obtain adversarial examples\n","        yp = model(x_adv)\n","        loss = loss_fn(yp, y)\n","        train_acc += (yp.argmax(dim=1) == y).sum().item()\n","        train_loss += loss.item() * x.shape[0]\n","        # store adversarial examples\n","        adv_ex = ((x_adv) * std + mean).clamp(0, 1) # to 0-1 scale\n","        adv_ex = (adv_ex * 255).clamp(0, 255) # 0-255 scale\n","        adv_ex = adv_ex.detach().cpu().data.numpy().round() # round to remove decimal part\n","        adv_ex = adv_ex.transpose((0, 2, 3, 1)) # transpose (bs, C, H, W) back to (bs, H, W, C)\n","        adv_examples = adv_ex if i == 0 else np.r_[adv_examples, adv_ex]\n","    return adv_examples, train_acc / len(loader.dataset), train_loss / len(loader.dataset)\n","\n","# create directory which stores adversarial examples\n","def create_dir(data_dir, adv_dir, adv_examples, adv_names):\n","    if os.path.exists(adv_dir) is not True:\n","        _ = shutil.copytree(data_dir, adv_dir)\n","    for example, name in zip(adv_examples, adv_names):\n","        im = Image.fromarray(example.astype(np.uint8)) # image pixel value should be unsigned int\n","        im.save(os.path.join(adv_dir, name))"]},{"cell_type":"markdown","metadata":{"id":"r_pMkmPytX3k"},"source":["## Model / Loss Function\n","\n","Model list is available [here](https://github.com/osmr/imgclsmob/blob/master/pytorch/pytorchcv/model_provider.py). Please select models which has _cifar10 suffix. Some of the models cannot be accessed/loaded. You can safely skip them since TA's model will not use those kinds of models."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jwto8xbPtYzQ","outputId":"fa9c3c4e-7bfe-4d4e-c068-015a7c7a08b6","executionInfo":{"status":"ok","timestamp":1657028964302,"user_tz":-480,"elapsed":6233,"user":{"displayName":"天","userId":"11778751613550389138"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading /root/.torch/models/resnet110_cifar10-0369-4d6ca1fc.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.163/resnet110_cifar10-0369-4d6ca1fc.pth.zip...\n","benign_acc = 0.95000, benign_loss = 0.22678\n"]}],"source":["from pytorchcv.model_provider import get_model as ptcv_get_model\n","\n","model = ptcv_get_model('resnet110_cifar10', pretrained=True).to(device)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","benign_acc, benign_loss = epoch_benign(model, adv_loader, loss_fn)\n","print(f'benign_acc = {benign_acc:.5f}, benign_loss = {benign_loss:.5f}')"]},{"cell_type":"markdown","metadata":{"id":"uslb7GPchtMI"},"source":["## FGSM"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wQwPTVUIhuTS","outputId":"5d2c963e-18fc-4039-b5a0-5efc56e2961b","executionInfo":{"status":"ok","timestamp":1657028968557,"user_tz":-480,"elapsed":4260,"user":{"displayName":"天","userId":"11778751613550389138"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["fgsm_acc = 0.59000, fgsm_loss = 2.49272\n"]}],"source":["adv_examples, fgsm_acc, fgsm_loss = gen_adv_examples(model, adv_loader, fgsm, loss_fn)\n","print(f'fgsm_acc = {fgsm_acc:.5f}, fgsm_loss = {fgsm_loss:.5f}')\n","\n","create_dir(root, 'fgsm', adv_examples, adv_names)"]},{"cell_type":"markdown","metadata":{"id":"WXw6p0A6shZm"},"source":["## I-FGSM"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fUEsT06Iskt2","outputId":"dcbb05c7-d2b6-4133-df86-4f5f0748ecef","scrolled":true,"executionInfo":{"status":"ok","timestamp":1657028994333,"user_tz":-480,"elapsed":25780,"user":{"displayName":"天","userId":"11778751613550389138"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["ifgsm_acc = 0.01000, ifgsm_loss = 17.37887\n"]}],"source":["adv_examples, ifgsm_acc, ifgsm_loss = gen_adv_examples(model, adv_loader, ifgsm, loss_fn)\n","print(f'ifgsm_acc = {ifgsm_acc:.5f}, ifgsm_loss = {ifgsm_loss:.5f}')\n","\n","create_dir(root, 'ifgsm', adv_examples, adv_names)"]},{"cell_type":"markdown","metadata":{"id":"OVqBUzXtnk37"},"source":["## MI-FGSM"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kwkyo3Henk37","executionInfo":{"status":"ok","timestamp":1657029017527,"user_tz":-480,"elapsed":23198,"user":{"displayName":"天","userId":"11778751613550389138"}},"outputId":"c65c3f97-8442-4354-ddab-5fcfae2251b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["mifgsm_acc = 0.12500, mifgsm_loss = 11.98420\n"]}],"source":["adv_examples, ifgsm_acc, ifgsm_loss = gen_adv_examples(model, adv_loader, mifgsm, loss_fn)\n","print(f'mifgsm_acc = {ifgsm_acc:.5f}, mifgsm_loss = {ifgsm_loss:.5f}')\n","\n","create_dir(root, 'mifgsm', adv_examples, adv_names)"]},{"cell_type":"markdown","metadata":{"id":"DQ-nYkkYexEE"},"source":["## Compress the images\n","* Submit the .tgz file to [JudgeBoi](https://ml.ee.ntu.edu.tw/hw10/)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ItRo_S0M264N","executionInfo":{"status":"ok","timestamp":1657029018152,"user_tz":-480,"elapsed":633,"user":{"displayName":"天","userId":"11778751613550389138"}},"outputId":"b9085d2e-1189-421c-c14c-d61cc7e8a9d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/fgsm\n","airplane/\n","airplane/airplane1.png\n","airplane/airplane14.png\n","airplane/airplane9.png\n","airplane/airplane15.png\n","airplane/airplane13.png\n","airplane/airplane16.png\n","airplane/airplane6.png\n","airplane/airplane5.png\n","airplane/airplane12.png\n","airplane/airplane10.png\n","airplane/airplane3.png\n","airplane/airplane2.png\n","airplane/airplane19.png\n","airplane/airplane7.png\n","airplane/airplane8.png\n","airplane/airplane18.png\n","airplane/airplane20.png\n","airplane/airplane4.png\n","airplane/airplane17.png\n","airplane/airplane11.png\n","automobile/\n","automobile/automobile11.png\n","automobile/automobile17.png\n","automobile/automobile2.png\n","automobile/automobile9.png\n","automobile/automobile20.png\n","automobile/automobile6.png\n","automobile/automobile7.png\n","automobile/automobile8.png\n","automobile/automobile14.png\n","automobile/automobile10.png\n","automobile/automobile13.png\n","automobile/automobile19.png\n","automobile/automobile5.png\n","automobile/automobile15.png\n","automobile/automobile3.png\n","automobile/automobile18.png\n","automobile/automobile12.png\n","automobile/automobile1.png\n","automobile/automobile4.png\n","automobile/automobile16.png\n","bird/\n","bird/bird15.png\n","bird/bird20.png\n","bird/bird9.png\n","bird/bird7.png\n","bird/bird12.png\n","bird/bird5.png\n","bird/bird16.png\n","bird/bird6.png\n","bird/bird17.png\n","bird/bird3.png\n","bird/bird10.png\n","bird/bird18.png\n","bird/bird14.png\n","bird/bird13.png\n","bird/bird11.png\n","bird/bird19.png\n","bird/bird4.png\n","bird/bird1.png\n","bird/bird2.png\n","bird/bird8.png\n","cat/\n","cat/cat5.png\n","cat/cat4.png\n","cat/cat1.png\n","cat/cat9.png\n","cat/cat12.png\n","cat/cat11.png\n","cat/cat19.png\n","cat/cat13.png\n","cat/cat6.png\n","cat/cat15.png\n","cat/cat20.png\n","cat/cat7.png\n","cat/cat3.png\n","cat/cat2.png\n","cat/cat18.png\n","cat/cat8.png\n","cat/cat17.png\n","cat/cat16.png\n","cat/cat10.png\n","cat/cat14.png\n","deer/\n","deer/deer10.png\n","deer/deer1.png\n","deer/deer11.png\n","deer/deer2.png\n","deer/deer3.png\n","deer/deer17.png\n","deer/deer16.png\n","deer/deer5.png\n","deer/deer6.png\n","deer/deer7.png\n","deer/deer12.png\n","deer/deer4.png\n","deer/deer18.png\n","deer/deer19.png\n","deer/deer13.png\n","deer/deer8.png\n","deer/deer15.png\n","deer/deer20.png\n","deer/deer9.png\n","deer/deer14.png\n","dog/\n","dog/dog2.png\n","dog/dog19.png\n","dog/dog11.png\n","dog/dog9.png\n","dog/dog1.png\n","dog/dog12.png\n","dog/dog3.png\n","dog/dog18.png\n","dog/dog8.png\n","dog/dog5.png\n","dog/dog15.png\n","dog/dog16.png\n","dog/dog10.png\n","dog/dog17.png\n","dog/dog4.png\n","dog/dog20.png\n","dog/dog6.png\n","dog/dog14.png\n","dog/dog13.png\n","dog/dog7.png\n","frog/\n","frog/frog20.png\n","frog/frog5.png\n","frog/frog12.png\n","frog/frog3.png\n","frog/frog14.png\n","frog/frog9.png\n","frog/frog6.png\n","frog/frog15.png\n","frog/frog16.png\n","frog/frog18.png\n","frog/frog8.png\n","frog/frog13.png\n","frog/frog4.png\n","frog/frog19.png\n","frog/frog1.png\n","frog/frog10.png\n","frog/frog7.png\n","frog/frog11.png\n","frog/frog17.png\n","frog/frog2.png\n","horse/\n","horse/horse13.png\n","horse/horse11.png\n","horse/horse12.png\n","horse/horse3.png\n","horse/horse5.png\n","horse/horse18.png\n","horse/horse4.png\n","horse/horse19.png\n","horse/horse17.png\n","horse/horse20.png\n","horse/horse16.png\n","horse/horse14.png\n","horse/horse10.png\n","horse/horse7.png\n","horse/horse8.png\n","horse/horse1.png\n","horse/horse15.png\n","horse/horse9.png\n","horse/horse6.png\n","horse/horse2.png\n","ship/\n","ship/ship11.png\n","ship/ship15.png\n","ship/ship7.png\n","ship/ship19.png\n","ship/ship18.png\n","ship/ship20.png\n","ship/ship1.png\n","ship/ship5.png\n","ship/ship16.png\n","ship/ship6.png\n","ship/ship10.png\n","ship/ship2.png\n","ship/ship12.png\n","ship/ship9.png\n","ship/ship4.png\n","ship/ship17.png\n","ship/ship13.png\n","ship/ship14.png\n","ship/ship3.png\n","ship/ship8.png\n","truck/\n","truck/truck1.png\n","truck/truck20.png\n","truck/truck9.png\n","truck/truck2.png\n","truck/truck3.png\n","truck/truck15.png\n","truck/truck11.png\n","truck/truck18.png\n","truck/truck7.png\n","truck/truck16.png\n","truck/truck13.png\n","truck/truck4.png\n","truck/truck6.png\n","truck/truck17.png\n","truck/truck5.png\n","truck/truck14.png\n","truck/truck12.png\n","truck/truck8.png\n","truck/truck19.png\n","truck/truck10.png\n","/content\n","/content/ifgsm\n","airplane/\n","airplane/airplane1.png\n","airplane/airplane14.png\n","airplane/airplane9.png\n","airplane/airplane15.png\n","airplane/airplane13.png\n","airplane/airplane16.png\n","airplane/airplane6.png\n","airplane/airplane5.png\n","airplane/airplane12.png\n","airplane/airplane10.png\n","airplane/airplane3.png\n","airplane/airplane2.png\n","airplane/airplane19.png\n","airplane/airplane7.png\n","airplane/airplane8.png\n","airplane/airplane18.png\n","airplane/airplane20.png\n","airplane/airplane4.png\n","airplane/airplane17.png\n","airplane/airplane11.png\n","automobile/\n","automobile/automobile11.png\n","automobile/automobile17.png\n","automobile/automobile2.png\n","automobile/automobile9.png\n","automobile/automobile20.png\n","automobile/automobile6.png\n","automobile/automobile7.png\n","automobile/automobile8.png\n","automobile/automobile14.png\n","automobile/automobile10.png\n","automobile/automobile13.png\n","automobile/automobile19.png\n","automobile/automobile5.png\n","automobile/automobile15.png\n","automobile/automobile3.png\n","automobile/automobile18.png\n","automobile/automobile12.png\n","automobile/automobile1.png\n","automobile/automobile4.png\n","automobile/automobile16.png\n","bird/\n","bird/bird15.png\n","bird/bird20.png\n","bird/bird9.png\n","bird/bird7.png\n","bird/bird12.png\n","bird/bird5.png\n","bird/bird16.png\n","bird/bird6.png\n","bird/bird17.png\n","bird/bird3.png\n","bird/bird10.png\n","bird/bird18.png\n","bird/bird14.png\n","bird/bird13.png\n","bird/bird11.png\n","bird/bird19.png\n","bird/bird4.png\n","bird/bird1.png\n","bird/bird2.png\n","bird/bird8.png\n","cat/\n","cat/cat5.png\n","cat/cat4.png\n","cat/cat1.png\n","cat/cat9.png\n","cat/cat12.png\n","cat/cat11.png\n","cat/cat19.png\n","cat/cat13.png\n","cat/cat6.png\n","cat/cat15.png\n","cat/cat20.png\n","cat/cat7.png\n","cat/cat3.png\n","cat/cat2.png\n","cat/cat18.png\n","cat/cat8.png\n","cat/cat17.png\n","cat/cat16.png\n","cat/cat10.png\n","cat/cat14.png\n","deer/\n","deer/deer10.png\n","deer/deer1.png\n","deer/deer11.png\n","deer/deer2.png\n","deer/deer3.png\n","deer/deer17.png\n","deer/deer16.png\n","deer/deer5.png\n","deer/deer6.png\n","deer/deer7.png\n","deer/deer12.png\n","deer/deer4.png\n","deer/deer18.png\n","deer/deer19.png\n","deer/deer13.png\n","deer/deer8.png\n","deer/deer15.png\n","deer/deer20.png\n","deer/deer9.png\n","deer/deer14.png\n","dog/\n","dog/dog2.png\n","dog/dog19.png\n","dog/dog11.png\n","dog/dog9.png\n","dog/dog1.png\n","dog/dog12.png\n","dog/dog3.png\n","dog/dog18.png\n","dog/dog8.png\n","dog/dog5.png\n","dog/dog15.png\n","dog/dog16.png\n","dog/dog10.png\n","dog/dog17.png\n","dog/dog4.png\n","dog/dog20.png\n","dog/dog6.png\n","dog/dog14.png\n","dog/dog13.png\n","dog/dog7.png\n","frog/\n","frog/frog20.png\n","frog/frog5.png\n","frog/frog12.png\n","frog/frog3.png\n","frog/frog14.png\n","frog/frog9.png\n","frog/frog6.png\n","frog/frog15.png\n","frog/frog16.png\n","frog/frog18.png\n","frog/frog8.png\n","frog/frog13.png\n","frog/frog4.png\n","frog/frog19.png\n","frog/frog1.png\n","frog/frog10.png\n","frog/frog7.png\n","frog/frog11.png\n","frog/frog17.png\n","frog/frog2.png\n","horse/\n","horse/horse13.png\n","horse/horse11.png\n","horse/horse12.png\n","horse/horse3.png\n","horse/horse5.png\n","horse/horse18.png\n","horse/horse4.png\n","horse/horse19.png\n","horse/horse17.png\n","horse/horse20.png\n","horse/horse16.png\n","horse/horse14.png\n","horse/horse10.png\n","horse/horse7.png\n","horse/horse8.png\n","horse/horse1.png\n","horse/horse15.png\n","horse/horse9.png\n","horse/horse6.png\n","horse/horse2.png\n","ship/\n","ship/ship11.png\n","ship/ship15.png\n","ship/ship7.png\n","ship/ship19.png\n","ship/ship18.png\n","ship/ship20.png\n","ship/ship1.png\n","ship/ship5.png\n","ship/ship16.png\n","ship/ship6.png\n","ship/ship10.png\n","ship/ship2.png\n","ship/ship12.png\n","ship/ship9.png\n","ship/ship4.png\n","ship/ship17.png\n","ship/ship13.png\n","ship/ship14.png\n","ship/ship3.png\n","ship/ship8.png\n","truck/\n","truck/truck1.png\n","truck/truck20.png\n","truck/truck9.png\n","truck/truck2.png\n","truck/truck3.png\n","truck/truck15.png\n","truck/truck11.png\n","truck/truck18.png\n","truck/truck7.png\n","truck/truck16.png\n","truck/truck13.png\n","truck/truck4.png\n","truck/truck6.png\n","truck/truck17.png\n","truck/truck5.png\n","truck/truck14.png\n","truck/truck12.png\n","truck/truck8.png\n","truck/truck19.png\n","truck/truck10.png\n","/content\n"]}],"source":["%cd fgsm\n","!tar zcvf ../fgsm.tgz *\n","%cd ..\n","\n","%cd ifgsm\n","!tar zcvf ../ifgsm.tgz *\n","%cd .."]},{"cell_type":"markdown","metadata":{"id":"WLZLbebigCA2"},"source":["## Example of Ensemble Attack\n","* Ensemble multiple models as your proxy model to increase the black-box transferability ([paper](https://arxiv.org/abs/1611.02770))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n8-EgDPFnk38","executionInfo":{"status":"ok","timestamp":1657029019906,"user_tz":-480,"elapsed":1760,"user":{"displayName":"天","userId":"11778751613550389138"}},"outputId":"6ded356a-2710-42c8-9c24-9174b565cee8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'pytorch-cifar'...\n","remote: Enumerating objects: 382, done.\u001b[K\n","remote: Total 382 (delta 0), reused 0 (delta 0), pack-reused 382\u001b[K\n","Receiving objects: 100% (382/382), 85.69 KiB | 14.28 MiB/s, done.\n","Resolving deltas: 100% (195/195), done.\n"]}],"source":["!git clone https://github.com/kuangliu/pytorch-cifar.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"24if9SYInk38"},"outputs":[],"source":["# goto pytorch-cifar, open main.py. \n","#use resnet18, change epoch number=40 and run. python main.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a2V8vQcMnk38","executionInfo":{"status":"ok","timestamp":1657029019908,"user_tz":-480,"elapsed":20,"user":{"displayName":"天","userId":"11778751613550389138"}},"outputId":"45b9205f-fc20-46c1-aa1b-e453d021b28c"},"outputs":[{"output_type":"stream","name":"stdout","text":["cp: cannot stat 'pytorch-cifar/checkpoint/ckpt.pth': No such file or directory\n"]}],"source":["!cp pytorch-cifar/models/resnet.py resnet.py\n","!cp pytorch-cifar/checkpoint/ckpt.pth ckpt.pth"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"6u0bg9C7nk39","executionInfo":{"status":"error","timestamp":1657029019916,"user_tz":-480,"elapsed":23,"user":{"displayName":"天","userId":"11778751613550389138"}},"outputId":"78b2a909-7ec1-4694-ca32-129328f48494"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-38ea7879690b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mresnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResNet18\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mundertrain_resnet18\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ckpt.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'net'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mundertrain_resnet18\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'module.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ckpt.pth'"]}],"source":["from resnet import ResNet18\n","undertrain_resnet18 = ResNet18().cuda()\n","state_dict = torch.load('ckpt.pth')['net']\n","undertrain_resnet18.load_state_dict({k.replace('module.', ''):v for k, v in state_dict.items()})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gJcKiQNUgnPQ"},"outputs":[],"source":["class ensembleNet(nn.Module):\n","    def __init__(self, model_names):\n","        super().__init__()\n","        self.models = nn.ModuleList([ptcv_get_model(name, pretrained=True) for name in model_names])\n","        self.models.append(undertrain_resnet18)\n","        \n","    def forward(self, x):\n","        emsemble_logits = None\n","        for i, m in enumerate(self.models):\n","            emsemble_logits = m(x) if i == 0 else emsemble_logits + m(x)\n","        # TODO: sum up logits from multiple models  \n","        return emsemble_logits/len(self.models)"]},{"cell_type":"markdown","metadata":{"id":"yjfJwJKeeaR2"},"source":["* Construct your ensemble model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"stYFytogeIzI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657029045542,"user_tz":-480,"elapsed":3404,"user":{"displayName":"天","userId":"11778751613550389138"}},"outputId":"1dfe6cc5-5edd-4a80-cec7-aa2f205761f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading /root/.torch/models/nin_cifar10-0743-795b0824.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.175/nin_cifar10-0743-795b0824.pth.zip...\n","Downloading /root/.torch/models/resnet20_cifar10-0597-9b0024ac.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.163/resnet20_cifar10-0597-9b0024ac.pth.zip...\n","Downloading /root/.torch/models/preresnet20_cifar10-0651-76cec68d.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.164/preresnet20_cifar10-0651-76cec68d.pth.zip...\n"]},{"output_type":"execute_result","data":{"text/plain":["ensembleNet(\n","  (models): ModuleList(\n","    (0): CIFARNIN(\n","      (features): Sequential(\n","        (stage1): Sequential(\n","          (unit1): NINConv(\n","            (conv): Conv2d(3, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","            (activ): ReLU(inplace=True)\n","          )\n","          (unit2): NINConv(\n","            (conv): Conv2d(192, 160, kernel_size=(1, 1), stride=(1, 1))\n","            (activ): ReLU(inplace=True)\n","          )\n","          (unit3): NINConv(\n","            (conv): Conv2d(160, 96, kernel_size=(1, 1), stride=(1, 1))\n","            (activ): ReLU(inplace=True)\n","          )\n","        )\n","        (stage2): Sequential(\n","          (pool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","          (dropout2): Dropout(p=0.5, inplace=False)\n","          (unit1): NINConv(\n","            (conv): Conv2d(96, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","            (activ): ReLU(inplace=True)\n","          )\n","          (unit2): NINConv(\n","            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n","            (activ): ReLU(inplace=True)\n","          )\n","          (unit3): NINConv(\n","            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n","            (activ): ReLU(inplace=True)\n","          )\n","        )\n","        (stage3): Sequential(\n","          (pool3): AvgPool2d(kernel_size=3, stride=2, padding=1)\n","          (dropout3): Dropout(p=0.5, inplace=False)\n","          (unit1): NINConv(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (activ): ReLU(inplace=True)\n","          )\n","          (unit2): NINConv(\n","            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n","            (activ): ReLU(inplace=True)\n","          )\n","        )\n","      )\n","      (output): Sequential(\n","        (final_conv): NINConv(\n","          (conv): Conv2d(192, 10, kernel_size=(1, 1), stride=(1, 1))\n","          (activ): ReLU(inplace=True)\n","        )\n","        (final_pool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n","      )\n","    )\n","    (1): CIFARResNet(\n","      (features): Sequential(\n","        (init_block): ConvBlock(\n","          (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (activ): ReLU(inplace=True)\n","        )\n","        (stage1): Sequential(\n","          (unit1): ResUnit(\n","            (body): ResBlock(\n","              (conv1): ConvBlock(\n","                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","              )\n","              (conv2): ConvBlock(\n","                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              )\n","            )\n","            (activ): ReLU(inplace=True)\n","          )\n","          (unit2): ResUnit(\n","            (body): ResBlock(\n","              (conv1): ConvBlock(\n","                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","              )\n","              (conv2): ConvBlock(\n","                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              )\n","            )\n","            (activ): ReLU(inplace=True)\n","          )\n","          (unit3): ResUnit(\n","            (body): ResBlock(\n","              (conv1): ConvBlock(\n","                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","              )\n","              (conv2): ConvBlock(\n","                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              )\n","            )\n","            (activ): ReLU(inplace=True)\n","          )\n","        )\n","        (stage2): Sequential(\n","          (unit1): ResUnit(\n","            (body): ResBlock(\n","              (conv1): ConvBlock(\n","                (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","              )\n","              (conv2): ConvBlock(\n","                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              )\n","            )\n","            (identity_conv): ConvBlock(\n","              (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","            (activ): ReLU(inplace=True)\n","          )\n","          (unit2): ResUnit(\n","            (body): ResBlock(\n","              (conv1): ConvBlock(\n","                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","              )\n","              (conv2): ConvBlock(\n","                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              )\n","            )\n","            (activ): ReLU(inplace=True)\n","          )\n","          (unit3): ResUnit(\n","            (body): ResBlock(\n","              (conv1): ConvBlock(\n","                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","              )\n","              (conv2): ConvBlock(\n","                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              )\n","            )\n","            (activ): ReLU(inplace=True)\n","          )\n","        )\n","        (stage3): Sequential(\n","          (unit1): ResUnit(\n","            (body): ResBlock(\n","              (conv1): ConvBlock(\n","                (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","              )\n","              (conv2): ConvBlock(\n","                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              )\n","            )\n","            (identity_conv): ConvBlock(\n","              (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","            (activ): ReLU(inplace=True)\n","          )\n","          (unit2): ResUnit(\n","            (body): ResBlock(\n","              (conv1): ConvBlock(\n","                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","              )\n","              (conv2): ConvBlock(\n","                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              )\n","            )\n","            (activ): ReLU(inplace=True)\n","          )\n","          (unit3): ResUnit(\n","            (body): ResBlock(\n","              (conv1): ConvBlock(\n","                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","              )\n","              (conv2): ConvBlock(\n","                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              )\n","            )\n","            (activ): ReLU(inplace=True)\n","          )\n","        )\n","        (final_pool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n","      )\n","      (output): Linear(in_features=64, out_features=10, bias=True)\n","    )\n","    (2): CIFARPreResNet(\n","      (features): Sequential(\n","        (init_block): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (stage1): Sequential(\n","          (unit1): PreResUnit(\n","            (body): PreResBlock(\n","              (conv1): PreConvBlock(\n","                (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              )\n","              (conv2): PreConvBlock(\n","                (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              )\n","            )\n","          )\n","          (unit2): PreResUnit(\n","            (body): PreResBlock(\n","              (conv1): PreConvBlock(\n","                (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              )\n","              (conv2): PreConvBlock(\n","                (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              )\n","            )\n","          )\n","          (unit3): PreResUnit(\n","            (body): PreResBlock(\n","              (conv1): PreConvBlock(\n","                (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              )\n","              (conv2): PreConvBlock(\n","                (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              )\n","            )\n","          )\n","        )\n","        (stage2): Sequential(\n","          (unit1): PreResUnit(\n","            (body): PreResBlock(\n","              (conv1): PreConvBlock(\n","                (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              )\n","              (conv2): PreConvBlock(\n","                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              )\n","            )\n","            (identity_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          )\n","          (unit2): PreResUnit(\n","            (body): PreResBlock(\n","              (conv1): PreConvBlock(\n","                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              )\n","              (conv2): PreConvBlock(\n","                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              )\n","            )\n","          )\n","          (unit3): PreResUnit(\n","            (body): PreResBlock(\n","              (conv1): PreConvBlock(\n","                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              )\n","              (conv2): PreConvBlock(\n","                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              )\n","            )\n","          )\n","        )\n","        (stage3): Sequential(\n","          (unit1): PreResUnit(\n","            (body): PreResBlock(\n","              (conv1): PreConvBlock(\n","                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              )\n","              (conv2): PreConvBlock(\n","                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              )\n","            )\n","            (identity_conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          )\n","          (unit2): PreResUnit(\n","            (body): PreResBlock(\n","              (conv1): PreConvBlock(\n","                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              )\n","              (conv2): PreConvBlock(\n","                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              )\n","            )\n","          )\n","          (unit3): PreResUnit(\n","            (body): PreResBlock(\n","              (conv1): PreConvBlock(\n","                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              )\n","              (conv2): PreConvBlock(\n","                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                (activ): ReLU(inplace=True)\n","                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              )\n","            )\n","          )\n","        )\n","        (post_activ): PreResActivation(\n","          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (activ): ReLU(inplace=True)\n","        )\n","        (final_pool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n","      )\n","      (output): Linear(in_features=64, out_features=10, bias=True)\n","    )\n","    (3): ResNet(\n","      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (layer1): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (shortcut): Sequential()\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (shortcut): Sequential()\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (shortcut): Sequential(\n","            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (shortcut): Sequential()\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (shortcut): Sequential(\n","            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (shortcut): Sequential()\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (shortcut): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (shortcut): Sequential()\n","        )\n","      )\n","      (linear): Linear(in_features=512, out_features=10, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":19}],"source":["model_names = [\n","    'nin_cifar10',\n","    'resnet20_cifar10',\n","    'preresnet20_cifar10'\n","]\n","ensemble_model = ensembleNet(model_names).to(device)\n","ensemble_model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJ284W3znk39"},"outputs":[],"source":["from pytorchcv.model_provider import get_model as ptcv_get_model\n","\n","benign_acc, benign_loss = epoch_benign(ensemble_model, adv_loader, loss_fn)\n","print(f'benign_acc = {benign_acc:.5f}, benign_loss = {benign_loss:.5f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"JWW3dzZwnk3-","executionInfo":{"status":"ok","timestamp":1657029065845,"user_tz":-480,"elapsed":16896,"user":{"displayName":"天","userId":"11778751613550389138"}},"outputId":"c8f30bc1-66f8-44de-e71e-32c3c16692a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["ensemble_ifgsm_acc = 0.00000, ensemble_ifgsm_loss = 10.05273\n"]}],"source":["adv_examples, ifgsm_acc, ifgsm_loss = gen_adv_examples(ensemble_model, adv_loader, ifgsm, loss_fn)\n","print(f'ensemble_ifgsm_acc = {ifgsm_acc:.5f}, ensemble_ifgsm_loss = {ifgsm_loss:.5f}')\n","\n","create_dir(root, 'ensemble_ifgsm', adv_examples, adv_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-8fETRhnk3-","executionInfo":{"status":"ok","timestamp":1657029082178,"user_tz":-480,"elapsed":16336,"user":{"displayName":"天","userId":"11778751613550389138"}},"outputId":"851fe314-a368-4fc6-ebcd-31395f1b9589"},"outputs":[{"output_type":"stream","name":"stdout","text":["ensemble_mifgsm_acc = 0.01000, ensemble_mifgsm_loss = 9.10255\n"]}],"source":["adv_examples, ifgsm_acc, ifgsm_loss = gen_adv_examples(ensemble_model, adv_loader, mifgsm, loss_fn)\n","print(f'ensemble_mifgsm_acc = {ifgsm_acc:.5f}, ensemble_mifgsm_loss = {ifgsm_loss:.5f}')\n","\n","create_dir(root, 'ensemble_mifgsm', adv_examples, adv_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7RzMZ39tnk3-","executionInfo":{"status":"ok","timestamp":1657029123589,"user_tz":-480,"elapsed":41414,"user":{"displayName":"天","userId":"11778751613550389138"}},"outputId":"83f04806-09c0-4ced-a0aa-5f2fd7aae72b"},"outputs":[{"output_type":"stream","name":"stdout","text":["ensemble_dmi_mifgsm_acc = 0.00000, ensemble_dim_mifgsm_loss = 10.20335\n"]}],"source":["adv_examples, ifgsm_acc, ifgsm_loss = gen_adv_examples(ensemble_model, adv_loader, dmi_mifgsm, loss_fn)\n","print(f'ensemble_dmi_mifgsm_acc = {ifgsm_acc:.5f}, ensemble_dim_mifgsm_loss = {ifgsm_loss:.5f}')\n","\n","create_dir(root, 'ensemble_dmi_mifgsm', adv_examples, adv_names)"]},{"cell_type":"markdown","metadata":{"id":"0FM_S886kFd8"},"source":["## Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2FCuE2njkH1O"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","plt.figure(figsize=(10, 20))\n","cnt = 0\n","for i, cls_name in enumerate(classes):\n","    path = f'{cls_name}/{cls_name}1.png'\n","    # benign image\n","    cnt += 1\n","    plt.subplot(len(classes), 4, cnt)\n","    im = Image.open(f'./data/{path}')\n","    logit = model(transform(im).unsqueeze(0).to(device))[0]\n","    predict = logit.argmax(-1).item()\n","    prob = logit.softmax(-1)[predict].item()\n","    plt.title(f'benign: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n","    plt.axis('off')\n","    plt.imshow(np.array(im))\n","    # adversarial image\n","    cnt += 1\n","    plt.subplot(len(classes), 4, cnt)\n","    im = Image.open(f'./ensemble_ifgsm/{path}')\n","    logit = model(transform(im).unsqueeze(0).to(device))[0]\n","    predict = logit.argmax(-1).item()\n","    prob = logit.softmax(-1)[predict].item()\n","    plt.title(f'adversarial: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n","    plt.axis('off')\n","    plt.imshow(np.array(im))\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"FUmKa02Vmp29"},"source":["## Report Question\n","* Make sure you follow below setup: the source model is \"resnet110_cifar10\", applying the vanilla fgsm attack on `dog2.png`. You can find the perturbed image in `fgsm/dog2.png`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8NW8ntCKY3VY"},"outputs":[],"source":["# original image\n","path = f'dog/dog2.png'\n","im = Image.open(f'./data/{path}')\n","logit = model(transform(im).unsqueeze(0).to(device))[0]\n","predict = logit.argmax(-1).item()\n","prob = logit.softmax(-1)[predict].item()\n","plt.title(f'benign: dog2.png\\n{classes[predict]}: {prob:.2%}')\n","plt.axis('off')\n","plt.imshow(np.array(im))\n","plt.tight_layout()\n","plt.show()\n","\n","# adversarial image \n","adv_im = Image.open(f'./ensemble_dmi_mifgsm/{path}')\n","logit = model(transform(adv_im).unsqueeze(0).to(device))[0]\n","predict = logit.argmax(-1).item()\n","prob = logit.softmax(-1)[predict].item()\n","plt.title(f'adversarial: dog2.png\\n{classes[predict]}: {prob:.2%}')\n","plt.axis('off')\n","plt.imshow(np.array(adv_im))\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"2AQkofrTnePa"},"source":["## Passive Defense - JPEG compression\n","JPEG compression by imgaug package, compression rate set to 70\n","\n","Reference: https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.JpegCompression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sKuQaPp2mz7C"},"outputs":[],"source":["import imgaug.augmenters as iaa\n","\n","# pre-process image\n","x = transforms.ToTensor()(adv_im)*255\n","x = x.permute(1, 2, 0).numpy()\n","x = x.astype(np.uint8)\n","\n","# TODO: use \"imgaug\" package to perform JPEG compression (compression rate = 70)\n","compressed_x =  iaa.arithmetic.compress_jpeg(x, compression=70)\n","\n","logit = model(transform(compressed_x).unsqueeze(0).to(device))[0]\n","predict = logit.argmax(-1).item()\n","prob = logit.softmax(-1)[predict].item()\n","plt.title(f'JPEG adversarial: dog2.png\\n{classes[predict]}: {prob:.2%}')\n","plt.axis('off')\n","\n","\n","plt.imshow(compressed_x)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U6Xd03cLnk4A"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"10. ML2022_hw10-boss.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}